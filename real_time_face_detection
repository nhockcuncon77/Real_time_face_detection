from keras.models import load_model
from PIL import Image
import numpy as np
import cv2
from keras.preprocessing.image import img_to_array
from keras.preprocessing import image
#the following are to do with this interactive notebook code


from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks
import pylab # this allows you to control figure size
pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook

export_dir='age_model_pretrained.h5'
age_model = load_model(export_dir)

# summarize model.
age_model.summary()
# load and evaluate a saved model
export_dir='gender_model_pretrained.h5'
gender_model = load_model(export_dir)

# summarize model.
gender_model.summary()

export_dir='emotion_model_pretrained.h5'
emotion_model = load_model(export_dir)

# summarize model.
emotion_model.summary()

face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

class_labels= ['positive', 'negative', 'neutral']
gender_labels = ['Female', 'Male']
age_ranges = ['1-2', '3-9', '10-20', '66-116', '28-45', '46-65', '21-27']

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    labels = []

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_classifier.detectMultiScale(gray, 1.3, 5)

    for (x, y, w, h) in faces:
        cv2.rectangle(frame, (x, y), (x + w, y + h), (203, 12, 255), 2)
        roi_gray = gray[y:y + h, x:x + w]
        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation=cv2.INTER_AREA)

        # Get image ready for prediction
        roi = roi_gray.astype('float') / 255.0  # Scale
        roi = img_to_array(roi)
        roi = np.expand_dims(roi, axis=0)  # Expand dims to get it ready for prediction (1, 48, 48, 1)

        preds = emotion_model.predict(roi)[0]  # Yields one hot encoded result for 7 classes
        label = class_labels[preds.argmax()]  # Find the label
        label_position = (x, y)
        cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Gender
        roi_color = frame[y:y + h, x:x + w]
        roi_color = cv2.resize(roi_color, (100, 100), interpolation=cv2.INTER_AREA)
        gender_predict = gender_model.predict(np.array(roi_color).reshape(-1, 100, 100, 1))
        gender_predict = (gender_predict >= 0.5).astype(int)[:, 0]
        gender_label = gender_labels[gender_predict[0]]

        gender_label_position = (x, y + h + 50)  # 50 pixels below to move the label outside the face
        cv2.putText(frame, gender_label, gender_label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Age
        roi_color = frame[y:y + h, x:x + w]
        roi_color = cv2.resize(roi_color, (200, 200), interpolation=cv2.INTER_AREA)
        # age_predict = age_model.predict(np.array(roi_color).reshape(-1, 200, 200, 1))
        #
        # age_predict = (age_predict >= 0.6).astype(int)[:, 0]
        # age_label = age_ranges[age_predict[0]]
        age_input = roi_color.reshape(-1, 200, 200, 1)
        output_age = age_ranges[np.argmax(age_model.predict(age_input))]

        #age = round(age_predict[0, 0])
        age_label_position = (x + h, y + h)
        cv2.putText(frame, output_age, age_label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    cv2.imshow('Emotion Detector', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()